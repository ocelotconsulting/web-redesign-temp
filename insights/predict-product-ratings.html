<!DOCTYPE html><html lang="en" class="scroll-smooth"><head><meta charSet="utf-8"/><link rel="preload" as="style" href="/_next/static/css/c4acdf01ccc07fc3.css"/><link rel="preload" as="script" href="/_next/static/chunks/webpack-527576ff117bb29f.js"/><link rel="preload" as="script" href="/_next/static/chunks/framework-2c79e2a64abdb08b.js"/><link rel="preload" as="script" href="/_next/static/chunks/main-b727035df9d33797.js"/><link rel="preload" as="script" href="/_next/static/chunks/pages/_app-e9b35ea059c39d6c.js"/><link rel="preload" as="script" href="/_next/static/chunks/pages/insights/predict-product-ratings-d6bcefc784e57c75.js"/><link rel="preload" as="script" href="/_next/static/yo3mINIea42s1oz6L0drA/_buildManifest.js"/><link rel="preload" as="script" href="/_next/static/yo3mINIea42s1oz6L0drA/_ssgManifest.js"/><link rel="preload" href="/_next/static/media/36ecc5252b54dfe2-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/8d5cdbc97c8e67c0-s.p.ttf" as="font" type="font/ttf" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/2ca1d5c4cde0a745-s.p.eot" as="font" type="font/eot" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/7e593f285f211725-s.p.woff" as="font" type="font/woff" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/css/c4acdf01ccc07fc3.css" as="style"/><meta name="viewport" content="width=device-width"/><title>Ocelot Consulting</title><meta name="designed by" content="Fluid22"/><link rel="shortcut icon" href="https://www.ocelotconsulting.com/assets/ocelot.svg"/><meta property="og:description" content="Modern solutions for companies seeking to innovate"/><meta property="og:image" content="https://www.ocelotconsulting.com/assets/ocelot.svg"/><meta property="og:image:type" content="image/svg+xml"/><meta name="author" content="Khuyen Tran"/><meta name="description" content="Predict product Ratings with User-Based Collaborative Filtering"/><meta property="og:description" content="Predict product Ratings with User-Based Collaborative Filtering"/><meta name="twitter:description" content="Predict product Ratings with User-Based Collaborative Filtering"/><meta property="og:type" content="website"/><meta property="og:title" content="Predict product Ratings with User-Based Collaborative Filtering"/><meta name="twitter:card" content="summary"/><meta name="twitter:site" content="@ocelot_llc"/><meta name="twitter:title" content="Predict product Ratings with User-Based Collaborative Filtering"/><meta property="og:url" content="https://www.ocelotconsulting.com/insights/predict-product-ratings"/><meta property="og:image" content="https://www.ocelotconsulting.com/assets/insights/2022-03-31-predict-product-ratings/mean_rating.gif"/><meta name="twitter:image" content="https://www.ocelotconsulting.com/assets/insights/2022-03-31-predict-product-ratings/mean_rating.gif"/><meta name="next-head-count" content="20"/><link rel="stylesheet" href="/_next/static/css/c4acdf01ccc07fc3.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-527576ff117bb29f.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-b727035df9d33797.js" defer=""></script><script src="/_next/static/chunks/pages/_app-e9b35ea059c39d6c.js" defer=""></script><script src="/_next/static/chunks/pages/insights/predict-product-ratings-d6bcefc784e57c75.js" defer=""></script><script src="/_next/static/yo3mINIea42s1oz6L0drA/_buildManifest.js" defer=""></script><script src="/_next/static/yo3mINIea42s1oz6L0drA/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="__className_5f60e9"><header class="bg-black py-3 px-4 sticky top-0 z-30"><div class="container mx-auto flex justify-between items-center"><div class="w-full max-w-[230px]"><a href="/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 215 62.03"><g id="uuid-36b4f38d-82ab-4769-85a6-1757a5d82573" data-name="uuid-6f1e76c6-871c-4fd5-95c0-b7dc6214758d"><g id="uuid-7d66c6dc-fc9e-4ba1-b833-65066a7c4247" data-name="uuid-29bab21a-6fc1-46ac-aa88-74035bc2c5b9"><g id="uuid-b8891b53-f348-47c3-9d92-7338778cfcf4" data-name="uuid-4751f6df-72ec-41a6-a073-cf1f1b1dd6bc"><path id="uuid-e3d9be24-0379-461e-9289-5bbd376c2387" data-name="uuid-29c2d842-6d1f-44d3-9950-638fc274bebd" d="m31.13,0c5.08,0,9.87,1.22,14.11,3.38-1.55,1.95-2.6,4.54-4.88,5.31-2.94.99-6.07-1.51-9.17-1.55-3.38-.04-6.84,2.36-10.06,1.31-2.1-.68-3-3.08-4.32-4.96C21.1,1.26,25.97,0,31.13,0m26.53,14.83c2.92,4.74,4.61,10.32,4.61,16.3,0,15.17-10.86,27.81-25.22,30.57,1.12-.49,2.19-1.11,3.07-1.93.46-.42-.04-1.3.27-1.84.26-.46,1.02-.44,1.3-.89.56-.87.5-2.06,1.11-2.89.67-.92,1.77-1.44,2.62-2.2.5-.45.94-.96,1.43-1.43,2.85-2.73,6.51-4.8,8.57-8.15,1.74-2.82,2.23-6.34,2.38-9.64.13-2.73-1.14-5.34-1.55-8.04-.21-1.36-.6-2.77-.3-4.11.22-1,1.53-1.51,1.78-2.5.27-1.05-.02-2.16-.08-3.26m-30.42,47.19C11.88,60.11,0,47.01,0,31.13c0-5.93,1.66-11.48,4.55-16.2.03,1.2-.09,2.42.22,3.57.2.74,1.2,1.06,1.43,1.79.34,1.1.37,2.31.18,3.45-.29,1.77-1.34,3.35-1.61,5.12-.34,2.26-.58,4.6-.18,6.85.43,2.46,1.14,5.01,2.62,7.02,2.43,3.3,5.83,5.76,8.84,8.54,1.09,1.01,2.49,1.67,3.44,2.81.47.56.23,1.49.62,2.1.46.73,1.41,1.07,1.87,1.81.43.7.03,1.91.71,2.37,1.34.91,2.96,1.3,4.56,1.66" fill="#f60" fill-rule="evenodd"></path></g><g id="uuid-ce6c619f-feea-4dcb-9b23-c56e8af9b92a" data-name="uuid-178258df-3ee5-4b8a-85c8-9f993d6c858e"><path id="uuid-ddc55242-3c18-4ef0-b432-020824885082" data-name="uuid-653abd23-601c-4ba5-a9d5-31d185e024e6" d="m7.41,16.63c-.32-2.31-1.47-4.56-1.27-6.88.15-1.71.99-3.47,2.28-4.61,1.07-.94,2.72-1.21,4.13-1.06,1.68.18,3.34.96,4.66,2.01,1.99,1.58,2.62,4.93,5.03,5.72,2.86.93,5.94-1.2,8.95-1.17,2.76.03,5.54,2.26,8.15,1.38,2.65-.9,3.44-4.55,5.77-6.09,1.78-1.18,4.02-1.59,6.14-1.8.87-.09,1.85.31,2.44.95,1.13,1.25,2.28,2.76,2.44,4.45.22,2.42-1.08,4.74-1.38,7.15-.15,1.23.36,2.51.05,3.71-.23.88-1.39,1.34-1.59,2.22-.27,1.19.08,2.45.27,3.65.37,2.4,1.49,4.73,1.38,7.15-.14,2.94-.57,6.07-2.12,8.58-1.84,2.99-5.09,4.83-7.63,7.26-.43.42-.82.87-1.27,1.27-.75.68-1.73,1.14-2.33,1.96-.54.74-.49,1.8-.99,2.57-.25.39-.93.38-1.16.79-.27.48.17,1.26-.24,1.63-1.09,1-2.47,1.68-3.87,2.16-1.04.36-2.19.31-3.29.32-1.13,0-2.27,0-3.37-.26-1.71-.4-3.53-.7-4.98-1.69-.61-.41-.25-1.48-.63-2.11-.4-.65-1.25-.96-1.66-1.61-.35-.55-.14-1.37-.55-1.87-.84-1.02-2.09-1.61-3.06-2.5-2.68-2.47-5.7-4.66-7.86-7.6-1.32-1.79-1.94-4.06-2.33-6.25-.35-2-.14-4.08.16-6.09.23-1.57,1.17-2.98,1.43-4.55.17-1.01.14-2.09-.16-3.07-.2-.65-1.09-.93-1.27-1.59-.36-1.33-.07-2.76-.27-4.13" fill="#e0e0e0" fill-rule="evenodd"></path></g><g id="uuid-803098d2-eb8a-4d45-9390-6d7443b5f865" data-name="uuid-4a710bf9-375f-4b82-9254-04a9df0be943"><path id="uuid-0b0c7fdc-0632-4883-9269-254ef729e5e0" data-name="uuid-4fd63ea7-1664-45b6-b611-482476f0213d" d="m84.16,8.28c4.03,0,7.4,1.35,10.12,4.03,2.71,2.69,4.07,6.01,4.07,9.94s-1.35,7.2-4.07,9.92c-2.71,2.72-6.01,4.07-9.91,4.07s-7.27-1.35-9.99-4.05c-2.71-2.7-4.07-5.97-4.07-9.81,0-2.56.62-4.93,1.85-7.11,1.24-2.19,2.92-3.89,5.06-5.13,2.14-1.24,4.45-1.85,6.93-1.85m.13,2.61c-1.97,0-3.83.51-5.6,1.54-1.76,1.02-3.13,2.41-4.13,4.14-.99,1.74-1.48,3.68-1.48,5.81,0,3.16,1.09,5.83,3.29,8.01,2.19,2.17,4.83,3.26,7.92,3.26,2.06,0,3.97-.5,5.73-1.5,1.75-1,3.13-2.37,4.11-4.11.98-1.74,1.48-3.67,1.48-5.79s-.49-4.02-1.48-5.73c-.98-1.71-2.37-3.07-4.15-4.1-1.78-1.02-3.68-1.54-5.68-1.54m44.2,3l-2.1,1.61c-1.16-1.51-2.55-2.65-4.17-3.43-1.62-.78-3.4-1.17-5.35-1.17-2.12,0-4.09.51-5.9,1.53-1.81,1.02-3.21,2.39-4.21,4.11-.99,1.72-1.5,3.66-1.5,5.8,0,3.25,1.11,5.96,3.34,8.13,2.22,2.17,5.04,3.26,8.43,3.26,3.73,0,6.85-1.46,9.35-4.38l2.1,1.59c-1.33,1.69-2.98,3-4.97,3.92-1.98.93-4.2,1.38-6.65,1.38-4.66,0-8.33-1.55-11.02-4.65-2.26-2.61-3.39-5.78-3.39-9.48,0-3.9,1.37-7.17,4.1-9.84,2.73-2.66,6.15-3.99,10.27-3.99,2.49,0,4.73.49,6.73,1.48,2,.98,3.65,2.36,4.92,4.13m5.36-4.94h15.26v2.63h-12.6v8.33h12.49v2.61h-12.49v10.44h12.49v2.63h-15.16V8.94h0Zm19.86,0h2.68v24.06h10.22v2.57h-12.9V8.94h0Zm29.81-.67c4.03,0,7.4,1.35,10.12,4.03,2.71,2.69,4.07,6.01,4.07,9.94s-1.35,7.2-4.07,9.92c-2.71,2.72-6.01,4.07-9.91,4.07s-7.27-1.35-9.99-4.05c-2.71-2.7-4.07-5.97-4.07-9.81,0-2.56.62-4.93,1.85-7.11,1.24-2.19,2.92-3.89,5.06-5.13,2.14-1.24,4.45-1.85,6.93-1.85m.13,2.61c-1.97,0-3.83.51-5.6,1.54-1.76,1.02-3.13,2.41-4.13,4.14-.99,1.74-1.48,3.68-1.48,5.81,0,3.16,1.09,5.83,3.29,8.01,2.19,2.17,4.83,3.26,7.92,3.26,2.06,0,3.97-.5,5.73-1.5,1.76-1,3.12-2.37,4.11-4.11.98-1.74,1.48-3.67,1.48-5.79s-.49-4.02-1.48-5.73c-.98-1.71-2.37-3.07-4.15-4.1-1.78-1.02-3.68-1.54-5.68-1.54m16.76.65v-2.59h14.61v2.59h-5.94v24.04h-2.71V11.53h-5.96Z" fill="#e0e0e0"></path></g><g id="uuid-d7cf37d0-f044-4850-9a95-88987b5e275c" data-name="uuid-7f947cbe-8809-47f8-b515-3a5bf33c37c5"><path id="uuid-9146962c-1316-438e-8bb6-ac9a5dc1a957" data-name="uuid-dfcddcc4-7f8f-4ead-97ba-0cc39733b4c2" d="m79.4,45.95l-.73.56c-.4-.53-.89-.92-1.45-1.2s-1.19-.41-1.87-.41c-.74,0-1.43.18-2.06.53-.63.36-1.12.83-1.47,1.43-.35.6-.52,1.28-.52,2.03,0,1.13.39,2.08,1.17,2.84.78.76,1.76,1.14,2.94,1.14,1.3,0,2.39-.51,3.27-1.53l.73.56c-.46.59-1.04,1.05-1.73,1.37-.69.32-1.47.48-2.32.48-1.63,0-2.91-.54-3.85-1.62-.79-.91-1.18-2.02-1.18-3.31,0-1.36.48-2.5,1.43-3.44.95-.93,2.15-1.39,3.59-1.39.87,0,1.65.17,2.35.52.7.34,1.27.82,1.72,1.44m13.46-1.96c1.41,0,2.58.47,3.53,1.41.95.94,1.42,2.1,1.42,3.47s-.47,2.52-1.42,3.46c-.95.95-2.1,1.42-3.46,1.42s-2.54-.47-3.49-1.41c-.95-.94-1.42-2.09-1.42-3.43,0-.89.22-1.72.65-2.48.43-.76,1.02-1.36,1.77-1.79.75-.43,1.55-.65,2.42-.65m.05.91c-.69,0-1.34.18-1.95.54-.61.36-1.09.84-1.44,1.45-.34.61-.52,1.28-.52,2.03,0,1.1.38,2.04,1.15,2.8.76.76,1.69,1.14,2.77,1.14.72,0,1.39-.17,2-.52.61-.35,1.09-.83,1.44-1.44.34-.61.52-1.28.52-2.02s-.17-1.4-.52-2c-.34-.59-.83-1.07-1.45-1.43-.62-.36-1.29-.54-1.99-.54m13.95,8.62v-9.3h.2l6.18,7.12v-7.12h.92v9.3h-.21l-6.13-7.03v7.03h-.97Zm15.77-1.73l.79-.47c.56,1.02,1.2,1.53,1.93,1.53.31,0,.6-.07.88-.22.27-.14.48-.34.63-.59.14-.24.22-.5.22-.78,0-.31-.11-.62-.32-.92-.29-.41-.82-.91-1.59-1.49-.77-.59-1.26-1.01-1.45-1.27-.33-.44-.49-.91-.49-1.42,0-.41.1-.77.29-1.11s.47-.59.82-.79c.35-.19.73-.29,1.14-.29.44,0,.85.11,1.23.32.38.22.79.62,1.21,1.2l-.76.58c-.35-.46-.65-.77-.9-.92-.25-.15-.52-.22-.81-.22-.38,0-.68.11-.92.34-.24.23-.36.51-.36.84,0,.2.04.4.12.59.09.19.24.39.46.62.12.12.52.43,1.2.93.81.59,1.36,1.12,1.66,1.59.3.46.45.93.45,1.4,0,.68-.26,1.26-.77,1.76-.51.5-1.13.75-1.87.75-.57,0-1.08-.15-1.54-.45-.46-.3-.88-.81-1.27-1.51m14.6-7.57h.93v5.61c0,.67.01,1.08.04,1.24.05.37.16.67.32.92.17.25.43.45.78.62.35.16.7.25,1.06.25.31,0,.6-.06.88-.2.28-.13.52-.31.71-.54.19-.23.33-.51.42-.84.06-.24.1-.72.1-1.45v-5.61h.93v5.61c0,.83-.08,1.5-.24,2.01s-.49.96-.97,1.34c-.49.38-1.08.57-1.77.57-.75,0-1.39-.18-1.93-.54s-.89-.83-1.08-1.42c-.11-.36-.17-1.02-.17-1.96v-5.61h0Zm15.61,0h.94v8.4h3.57v.9h-4.51v-9.3h0Zm12.22.91v-.9h5.1v.9h-2.07v8.39h-.95v-8.39h-2.08Zm13.47-.9h.93v9.3h-.93v-9.3Zm10.23,9.3v-9.3h.2l6.18,7.12v-7.12h.92v9.3h-.21l-6.13-7.03v7.03h-.96,0Zm25.7-7.74l-.72.68c-.52-.51-1.09-.9-1.7-1.16s-1.22-.39-1.8-.39c-.73,0-1.42.18-2.08.54-.66.36-1.17.84-1.53,1.45-.36.61-.54,1.26-.54,1.94s.19,1.36.56,1.99c.38.63.89,1.13,1.55,1.49.66.36,1.39.54,2.17.54.96,0,1.77-.27,2.43-.81.66-.54,1.05-1.24,1.18-2.1h-2.96v-.9h4.01c0,1.44-.43,2.58-1.28,3.42-.84.85-1.97,1.27-3.39,1.27-1.72,0-3.08-.59-4.08-1.76-.77-.9-1.16-1.94-1.16-3.13,0-.88.22-1.7.66-2.46.44-.76,1.05-1.35,1.82-1.78.77-.43,1.64-.64,2.62-.64.79,0,1.53.14,2.22.43.7.28,1.37.74,2.04,1.37" fill="#e0e0e0"></path></g></g></g></svg></a></div><button><svg class="w-6 lg:hidden fill-white" xmlns="http://www.w3.org/2000/svg" x="0px" y="0px" width="42.063px" height="27.083px" viewBox="0 0 42.063 27.083" xml:space="preserve"><path d="M39.875,3.482H2.5c-0.829,0-1.5-0.671-1.5-1.5s0.671-1.5,1.5-1.5h37.375c0.828,0,1.5,0.671,1.5,1.5 S40.703,3.482,39.875,3.482z"></path><path d="M39.875,15.201H2.5c-0.829,0-1.5-0.671-1.5-1.5s0.671-1.5,1.5-1.5h37.375c0.828,0,1.5,0.671,1.5,1.5 S40.703,15.201,39.875,15.201z"></path><path d="M39.875,26.919H2.5c-0.829,0-1.5-0.672-1.5-1.5s0.671-1.5,1.5-1.5h37.375c0.828,0,1.5,0.672,1.5,1.5 S40.703,26.919,39.875,26.919z"></path><g></g><g></g><g></g><g></g><g></g><g></g></svg></button><nav class="hidden lg:block text-white"><ul class="flex"><li class="group px-8 py-4 text-lg relative"><a href="/services">Services</a><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="chevron-down" class="svg-inline--fa fa-chevron-down ml-2 text-sm" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M233.4 406.6c12.5 12.5 32.8 12.5 45.3 0l192-192c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L256 338.7 86.6 169.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l192 192z"></path></svg><div class="hidden group-hover:block absolute bg-black min-w-[200px] top-full left-0"><ul><li><a class="block px-8 py-2 whitespace-nowrap hover:bg-white/20" href="/services">All Services</a></li><li><a class="block px-8 py-2 whitespace-nowrap hover:bg-white/20" href="/services/cloud-transformation">Cloud Transformation</a></li><li><a class="block px-8 py-2 whitespace-nowrap hover:bg-white/20" href="/services/full-stack-development">Full-Stack Development</a></li><li><a class="block px-8 py-2 whitespace-nowrap hover:bg-white/20" href="/services/data-engineering">Data Engineering</a></li><li><a class="block px-8 py-2 whitespace-nowrap hover:bg-white/20" href="/services/data-science">Data Science</a></li><li><a class="block px-8 py-2 whitespace-nowrap hover:bg-white/20" href="/services/strategy-execution">Strategy &amp; Execution</a></li></ul></div></li><li class="px-8 py-4 text-lg"><a href="/about">About</a></li><li class="px-8 py-4 text-lg"><a href="/case-studies">Case Studies</a></li><li class="px-8 py-4 text-lg"><a href="/careers">Careers</a></li><li class="px-8 py-4 text-lg"><a href="/insights">Insights</a></li><li class="pl-8 py-4 text-lg"><a href="#">Contact</a></li></ul></nav></div></header><main><section class="relative py-14 md:py-20 px-5 bg-cover bg-center md:min-h-[370px] flex flex-col justify-center" style="background-image:url(/assets/insights/2022-03-31-predict-product-ratings/mean_rating.gif)"><div class="absolute inset-0 bg-black/40"></div><div class="relative container mx-auto "><h1 class="text-4xl md:text-7xl font-bold text-white md:text-left text-center">Predict product Ratings with User-Based Collaborative Filtering</h1><p class="text-white"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="calendar" class="svg-inline--fa fa-calendar text-accent mr-2" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M96 32V64H48C21.5 64 0 85.5 0 112v48H448V112c0-26.5-21.5-48-48-48H352V32c0-17.7-14.3-32-32-32s-32 14.3-32 32V64H160V32c0-17.7-14.3-32-32-32S96 14.3 96 32zM448 192H0V464c0 26.5 21.5 48 48 48H400c26.5 0 48-21.5 48-48V192z"></path></svg>2022-03-31 10:00:00</p><p class="text-white"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="circle-user" class="svg-inline--fa fa-circle-user text-accent mr-2" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M399 384.2C376.9 345.8 335.4 320 288 320H224c-47.4 0-88.9 25.8-111 64.2c35.2 39.2 86.2 63.8 143 63.8s107.8-24.7 143-63.8zM0 256a256 256 0 1 1 512 0A256 256 0 1 1 0 256zm256 16a72 72 0 1 0 0-144 72 72 0 1 0 0 144z"></path></svg>By <!-- -->Khuyen Tran</p></div></section><section class="relative py-14 md:py-20 px-5 "><div class="relative container mx-auto "><h2 class="text-3xl font-bold text-black mb-4">Motivation</h2>
<p class="mb-4">Imagine you have a database of product ratings from different users. There are some products in the system that your users haven&#x27;t bought. How do recommend new and relevant products to your users using this data?</p>
<p class="mb-4"><img src="/assets/insights/2022-03-31-predict-product-ratings/data.png" alt=""/></p>
<p class="mb-4">One straightforward approach is to guess the rating of user 1 on a product using the rating of user 2 on the same product. To increase the chance of guessing it right, user 2 should have similar rating behaviors to user 1.</p>
<p class="mb-4"><img src="/assets/insights/2022-03-31-predict-product-ratings/table.gif" alt=""/></p>
<p class="mb-4">After predicting all ratings, we will then recommend user 1 the products that are predicted to be highly rated by user 1.</p>
<p class="mb-4">The approach above is a simplified version of user-based collaborative filtering, where we use similarities between users to provide recommendations.</p>
<p class="mb-4">In this article, we will use collaborative filtering to fill in the missing ratings on a real product database.</p>
<h2 class="text-3xl font-bold text-black mb-4">Get the Data</h2>
<p class="mb-4">We will work with a sample data I created. The data can be downloaded <a style="color:#3273dc" href="https://github.com/ocelotconsulting/cereal-rating/blob/main/data/cereal_ratings.csv">here</a>.</p>
<p class="mb-4">After saving the data under the directory <code>data</code>, load the data:</p>
<div class="remark-highlight"><pre class="p-4 mb-4 bg-black"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
ratings_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">&#x27;../data/cereal_ratings.csv&#x27;</span><span class="token punctuation">,</span> index_col<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
ratings_df
</code></pre></div>
<p class="mb-4"><img src="/assets/insights/2022-03-31-predict-product-ratings/data.png" alt=""/></p>
<p class="mb-4">Note that there are some missing values in this data. We will start with finding the similarity between each pair of users.</p>
<h2 class="text-3xl font-bold text-black mb-4">Find Similarities Between Users</h2>
<p class="mb-4">We&#x27;ll use the <a style="color:#3273dc" href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson correlation coefficient</a> to find the correlation between users based on their rated products.</p>
<p class="mb-4">If two users give exactly the same ratings, the Pearson correlation is 1.</p>
<div class="remark-highlight"><pre class="p-4 mb-4 bg-black"><code class="language-python">user1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>
user2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>
np<span class="token punctuation">.</span>corrcoef<span class="token punctuation">(</span>user1<span class="token punctuation">,</span> user2<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
</code></pre></div>
<div class="remark-highlight"><pre class="p-4 mb-4 bg-black"><code class="language-bash"><span class="token number">1.0</span>
</code></pre></div>
<p class="mb-4">If the relative product ratings of two users increase at the same rate, the correlation is still 1.</p>
<div class="remark-highlight"><pre class="p-4 mb-4 bg-black"><code class="language-python">user1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>
user2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span>
np<span class="token punctuation">.</span>corrcoef<span class="token punctuation">(</span>user1<span class="token punctuation">,</span> user2<span class="token punctuation">)</span>
</code></pre></div>
<div class="remark-highlight"><pre class="p-4 mb-4 bg-black"><code class="language-bash"><span class="token number">1.0</span>
</code></pre></div>
<p class="mb-4">If two users rate exactly opposite to each other, the correlation is -1.</p>
<div class="remark-highlight"><pre class="p-4 mb-4 bg-black"><code class="language-python">user1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>
user2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
np<span class="token punctuation">.</span>corrcoef<span class="token punctuation">(</span>user1<span class="token punctuation">,</span> user2<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
</code></pre></div>
<div class="remark-highlight"><pre class="p-4 mb-4 bg-black"><code class="language-bash"><span class="token parameter variable">-1</span>
</code></pre></div>
<p class="mb-4">Let&#x27;s use this method to create a function that finds a correlation between two users:</p>
<div class="remark-highlight"><pre class="p-4 mb-4 bg-black"><code class="language-python"><span class="token keyword">def</span> <span class="token function">find_correlation_between_two_users</span><span class="token punctuation">(</span>ratings_df<span class="token punctuation">:</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">,</span> user1<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> user2<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;Find correlation between two users based on their rated products using Pearson correlation&quot;&quot;&quot;</span>
    rated_products_by_both <span class="token operator">=</span> ratings_df<span class="token punctuation">[</span><span class="token punctuation">[</span>user1<span class="token punctuation">,</span> user2<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values
    user1_ratings <span class="token operator">=</span> rated_products_by_both<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
    user2_ratings <span class="token operator">=</span> rated_products_by_both<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span>corrcoef<span class="token punctuation">(</span>user1_ratings<span class="token punctuation">,</span> user2_ratings<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
</code></pre></div>
<p class="mb-4">Create a matrix that shows the similarities between all pairs of users:</p>
<div class="remark-highlight"><pre class="p-4 mb-4 bg-black"><code class="language-python"><span class="token keyword">def</span> <span class="token function">find_correlation_between_two_users</span><span class="token punctuation">(</span>ratings_df<span class="token punctuation">:</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">,</span> user1<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> user2<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;Find correlation between two users based on their rated products using Pearson correlation&quot;&quot;&quot;</span>
    rated_products_by_both <span class="token operator">=</span> ratings_df<span class="token punctuation">[</span><span class="token punctuation">[</span>user1<span class="token punctuation">,</span> user2<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values
    user1_ratings <span class="token operator">=</span> rated_products_by_both<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
    user2_ratings <span class="token operator">=</span> rated_products_by_both<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span>corrcoef<span class="token punctuation">(</span>user1_ratings<span class="token punctuation">,</span> user2_ratings<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
</code></pre></div>
<p class="mb-4"><img src="https://miro.medium.com/max/700/1*ZlwVV22bKTzbva0QsN0GSA.png" alt=""/></p>
<h2 class="text-3xl font-bold text-black mb-4">Get Similar Users</h2>
<p class="mb-4">Imagine we want to predict the rating of user 3 for product 1 based on the ratings of other users. We first want to select only the users who have rated product 1.</p>
<div class="remark-highlight"><pre class="p-4 mb-4 bg-black"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_rated_user_for_a_product</span><span class="token punctuation">(</span>ratings_df<span class="token punctuation">:</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">,</span> product<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> ratings_df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>product<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dropna<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>index<span class="token punctuation">.</span>values
</code></pre></div>
<p class="mb-4"><img src="/assets/insights/2022-03-31-predict-product-ratings/get_rated_users.gif" alt=""/></p>
<p class="mb-4">Next, we only pick the <em>k</em> number of users that are the most similar to user 3. We call these <em>k</em> number of users the <em>neighbors</em> of user 3.</p>
<div class="remark-highlight"><pre class="p-4 mb-4 bg-black"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_top_neighbors</span><span class="token punctuation">(</span>similarity_df<span class="token punctuation">:</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">,</span> user<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> rated_users<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> n_neighbors<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> similarity_df<span class="token punctuation">[</span>user<span class="token punctuation">]</span><span class="token punctuation">[</span>rated_users<span class="token punctuation">]</span><span class="token punctuation">.</span>nlargest<span class="token punctuation">(</span>n_neighbors<span class="token punctuation">)</span><span class="token punctuation">.</span>to_dict<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<p class="mb-4">In the example below, we set the number of neighbors to be 2.</p>
<p class="mb-4"><img src="/assets/insights/2022-03-31-predict-product-ratings/get_neighbors.gif" alt=""/></p>
<h2 class="text-3xl font-bold text-black mb-4">Get the Ratings of the Similar Users on a product</h2>
<p class="mb-4">Since different users might have different rating scales for the product that they like, we want to adjust for this bias by <strong>subtracting</strong> a rating of a user for <strong>a product</strong> by the <strong>mean</strong> ratings of that user for <strong>all products</strong>.</p>
<p class="mb-4"><img src="/assets/insights/2022-03-31-predict-product-ratings/why_5_stars.png" alt=""/></p>
<p class="mb-4">This means the rating of user ùë£ for the product ùëñ after adjusting for bias is:</p>
<p class="mb-4"><img src="https://miro.medium.com/max/653/1*D_Ty6HEsuHFUCCUaayqbMQ.png" alt=""/></p>
<div class="remark-highlight"><pre class="p-4 mb-4 bg-black"><code class="language-python"><span class="token keyword">def</span> <span class="token function">subtract_bias</span><span class="token punctuation">(</span>rating<span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token punctuation">,</span> mean_rating<span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> rating <span class="token operator">-</span> mean_rating


<span class="token keyword">def</span> <span class="token function">get_neighbor_rating_without_bias_per_product</span><span class="token punctuation">(</span>
    ratings_df<span class="token punctuation">:</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">,</span> user<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> product<span class="token punctuation">:</span> <span class="token builtin">str</span>
<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;Substract the rating of a user from the mean rating of that user to eliminate bias&quot;&quot;&quot;</span>
    mean_rating <span class="token operator">=</span> ratings_df<span class="token punctuation">[</span>user<span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
    rating <span class="token operator">=</span> ratings_df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>product<span class="token punctuation">,</span> user<span class="token punctuation">]</span>
    <span class="token keyword">return</span> subtract_bias<span class="token punctuation">(</span>rating<span class="token punctuation">,</span> mean_rating<span class="token punctuation">)</span>
    
<span class="token keyword">def</span> <span class="token function">get_ratings_of_neighbors</span><span class="token punctuation">(</span>ratings_df<span class="token punctuation">:</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">,</span> neighbors<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">,</span> product<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;Get the ratings of all neighbors after adjusting for biases&quot;&quot;&quot;</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span>
        get_neighbor_rating_without_bias_per_product<span class="token punctuation">(</span>ratings_df<span class="token punctuation">,</span> neighbor<span class="token punctuation">,</span> product<span class="token punctuation">)</span>
        <span class="token keyword">for</span> neighbor <span class="token keyword">in</span> neighbors
    <span class="token punctuation">]</span>
</code></pre></div>
<p class="mb-4">In the GIF below, since the mean rating of user 1 for all products is 1, we subtract the rating of user 1 for product 1 by 1. Since the mean rating of user 2 for all products is 4, we subtract the rating of user 2 for product 1 by 4.</p>
<p class="mb-4">Thus, the new ratings of users 1 and 2 for product 1 after adjusting for biases will be 2 stars and 1 star respectively.</p>
<p class="mb-4"><img src="https://miro.medium.com/max/700/1*DpsCOnS3UGClToxXxFm5Sg.gif" alt=""/></p>
<h2 class="text-3xl font-bold text-black mb-4">Get the Rating of a User for a product Based on the Ratings of Similar Users</h2>
<h2 class="text-3xl font-bold text-black mb-4"><strong>Get the Rating Before Adjusting for Bias</strong></h2>
<p class="mb-4">The rating of user ùë¢ for product ùëñ before adjusting for the bias is calculated by taking the weighted average of the ratings for product ùëñ from all neighbors ùë£.</p>
<p class="mb-4"><img src="https://miro.medium.com/max/700/1*ryRNWZgC7Pqesd9ueoObyg.png" alt=""/></p>
<div class="remark-highlight"><pre class="p-4 mb-4 bg-black"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_weighted_average_rating_of_neighbors</span><span class="token punctuation">(</span>ratings<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">,</span> neighbor_distance<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    weighted_sum <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>ratings<span class="token punctuation">)</span><span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>neighbor_distance<span class="token punctuation">)</span><span class="token punctuation">)</span>
    abs_neigbor_distance <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>neighbor_distance<span class="token punctuation">)</span>
    <span class="token keyword">return</span> weighted_sum <span class="token operator">/</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>abs_neigbor_distance<span class="token punctuation">)</span>
</code></pre></div>
<p class="mb-4">For example, the similarity of user 1 and user 3 is 0.8. The rating of user 1 for product 1 is 2. We multiply the adjusting rating of user 1 by their similarity of 0.8.</p>
<p class="mb-4">We can do the similar calculation for user 2. The table below summarizes the calculations.</p>
<p class="mb-4"><img src="/assets/insights/2022-03-31-predict-product-ratings/table2.png" alt=""/></p>
<p class="mb-4">We then divide the sum of these weighted ratings by the sum of 0.8 and 0.5.</p>
<p class="mb-4">The result of this calculation is the rating of user 3 for product 1 before adjusting for the bias.</p>
<p class="mb-4"><img src="https://miro.medium.com/max/700/1*xmxqBSacjmORm07sW6W8Uw.gif" alt=""/></p>
<h2 class="text-3xl font-bold text-black mb-4">Get the Rating After Adjusting for Bias</h2>
<p class="mb-4">Remember that we subtract the rating of each neighbor for a product by their mean rating to remove their bias?</p>
<p class="mb-4">To get the expected rating of user ùë¢ for product ùëñ, we will add the mean rating of user ùë¢ to the expected rating of user ùë¢ for product ùëñ before adjusting for bias.</p>
<p class="mb-4"><img src="https://miro.medium.com/max/648/1*4FR78m5gloOZ64w9VG1e3Q.png" alt=""/></p>
<div class="remark-highlight"><pre class="p-4 mb-4 bg-black"><code class="language-python"><span class="token keyword">def</span> <span class="token function">ger_user_rating</span><span class="token punctuation">(</span>ratings_df<span class="token punctuation">:</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">,</span> user<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> avg_neighbor_rating<span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    user_avg_rating <span class="token operator">=</span> ratings_df<span class="token punctuation">[</span>user<span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token builtin">round</span><span class="token punctuation">(</span>user_avg_rating <span class="token operator">+</span> avg_neighbor_rating<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
</code></pre></div>
<p class="mb-4">In the GIF below, the expected rating of user 3 for product 1 before adjusting for bias is 1.61, and the mean rating of user 3 for all products is 2. Taking the sum of 1.61 and 2 will give us 3.61.</p>
<p class="mb-4"><img src="/assets/insights/2022-03-31-predict-product-ratings/mean_rating.gif" alt=""/></p>
<h2 class="text-3xl font-bold text-black mb-4">Get the Missing Ratings of All Users</h2>
<p class="mb-4">Now we are ready to put all of the functions shown above into the function <code>predict_rating</code> . This function predicts the rating of a user for a product based on the ratings of that user&#x27;s neighbors.</p>
<div class="remark-highlight"><pre class="p-4 mb-4 bg-black"><code class="language-python"><span class="token keyword">def</span> <span class="token function">predict_rating</span><span class="token punctuation">(</span>
    df<span class="token punctuation">:</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">,</span>
    similarity_df<span class="token punctuation">:</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">,</span>
    user<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span>
    product<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span>
    n_neighbors<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;Predict the rating of a user for a product based on the ratings of neighbors&quot;&quot;&quot;</span>
    ratings_df <span class="token operator">=</span> df<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>

    rated_users <span class="token operator">=</span> get_rated_user_for_a_product<span class="token punctuation">(</span>ratings_df<span class="token punctuation">,</span> product<span class="token punctuation">)</span>

    top_neighbors_distance <span class="token operator">=</span> get_top_neighbors<span class="token punctuation">(</span>
        similarity_df<span class="token punctuation">,</span> user<span class="token punctuation">,</span> rated_users<span class="token punctuation">,</span> n_neighbors
    <span class="token punctuation">)</span>
    neighbors<span class="token punctuation">,</span> distance <span class="token operator">=</span> top_neighbors_distance<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> top_neighbors_distance<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Top </span><span class="token interpolation"><span class="token punctuation">{</span>n_neighbors<span class="token punctuation">}</span></span><span class="token string"> neighbors of user </span><span class="token interpolation"><span class="token punctuation">{</span>user<span class="token punctuation">}</span></span><span class="token string">, </span><span class="token interpolation"><span class="token punctuation">{</span>product<span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">list</span><span class="token punctuation">(</span>neighbors<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>

    ratings <span class="token operator">=</span> get_ratings_of_neighbors<span class="token punctuation">(</span>ratings_df<span class="token punctuation">,</span> neighbors<span class="token punctuation">,</span> product<span class="token punctuation">)</span>
    avg_neighbor_rating <span class="token operator">=</span> get_weighted_average_rating_of_neighbors<span class="token punctuation">(</span>
        ratings<span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">(</span>distance<span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

    <span class="token keyword">return</span> ger_user_rating<span class="token punctuation">(</span>ratings_df<span class="token punctuation">,</span> user<span class="token punctuation">,</span> avg_neighbor_rating<span class="token punctuation">)</span>
</code></pre></div>
<p class="mb-4">Use the <code>predict_rating</code> function to predict the ratings of all missing ratings:</p>
<div class="remark-highlight"><pre class="p-4 mb-4 bg-black"><code class="language-python">full_ratings <span class="token operator">=</span> ratings_df<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> user<span class="token punctuation">,</span> products <span class="token keyword">in</span> full_ratings<span class="token punctuation">.</span>iteritems<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> product <span class="token keyword">in</span> products<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> np<span class="token punctuation">.</span>isnan<span class="token punctuation">(</span>full_ratings<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>product<span class="token punctuation">,</span> user<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            full_ratings<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>product<span class="token punctuation">,</span> user<span class="token punctuation">]</span> <span class="token operator">=</span> predict_rating<span class="token punctuation">(</span>
                ratings_df<span class="token punctuation">,</span> similarity_df<span class="token punctuation">,</span> user<span class="token punctuation">,</span> product
            <span class="token punctuation">)</span>
</code></pre></div>
<div class="remark-highlight"><pre class="p-4 mb-4 bg-black"><code class="language-bash">Top <span class="token number">2</span> neighbors of user <span class="token number">30</span>, All-Bran: <span class="token punctuation">[</span><span class="token string">&#x27;509&#x27;</span>, <span class="token string">&#x27;15&#x27;</span><span class="token punctuation">]</span>
Top <span class="token number">2</span> neighbors of user <span class="token number">311</span>, Apple Cinnamon Cheerios: <span class="token punctuation">[</span><span class="token string">&#x27;452&#x27;</span>, <span class="token string">&#x27;73&#x27;</span><span class="token punctuation">]</span>
Top <span class="token number">2</span> neighbors of user <span class="token number">311</span>, Cap<span class="token string">&#x27;n&#x27;</span>Crunch: <span class="token punctuation">[</span><span class="token string">&#x27;452&#x27;</span>, <span class="token string">&#x27;73&#x27;</span><span class="token punctuation">]</span>
Top <span class="token number">2</span> neighbors of user <span class="token number">452</span>, <span class="token number">100</span>% Bran: <span class="token punctuation">[</span><span class="token string">&#x27;468&#x27;</span>, <span class="token string">&#x27;311&#x27;</span><span class="token punctuation">]</span>
Top <span class="token number">2</span> neighbors of user <span class="token number">452</span>, All-Bran with Extra Fiber: <span class="token punctuation">[</span><span class="token string">&#x27;468&#x27;</span>, <span class="token string">&#x27;311&#x27;</span><span class="token punctuation">]</span>
Top <span class="token number">2</span> neighbors of user <span class="token number">452</span>, Cinnamon Toast Crunch: <span class="token punctuation">[</span><span class="token string">&#x27;468&#x27;</span>, <span class="token string">&#x27;311&#x27;</span><span class="token punctuation">]</span>
Top <span class="token number">2</span> neighbors of user <span class="token number">452</span>, Clusters: <span class="token punctuation">[</span><span class="token string">&#x27;468&#x27;</span>, <span class="token string">&#x27;311&#x27;</span><span class="token punctuation">]</span>
Top <span class="token number">2</span> neighbors of user <span class="token number">452</span>, Cocoa Puffs: <span class="token punctuation">[</span><span class="token string">&#x27;468&#x27;</span>, <span class="token string">&#x27;311&#x27;</span><span class="token punctuation">]</span>
Top <span class="token number">2</span> neighbors of user <span class="token number">468</span>, Bran Flakes: <span class="token punctuation">[</span><span class="token string">&#x27;452&#x27;</span>, <span class="token string">&#x27;624&#x27;</span><span class="token punctuation">]</span>
Top <span class="token number">2</span> neighbors of user <span class="token number">547</span>, <span class="token number">100</span>% Natural Bran: <span class="token punctuation">[</span><span class="token string">&#x27;509&#x27;</span>, <span class="token string">&#x27;468&#x27;</span><span class="token punctuation">]</span>
Top <span class="token number">2</span> neighbors of user <span class="token number">547</span>, Basic <span class="token number">4</span>: <span class="token punctuation">[</span><span class="token string">&#x27;509&#x27;</span>, <span class="token string">&#x27;468&#x27;</span><span class="token punctuation">]</span>
Top <span class="token number">2</span> neighbors of user <span class="token number">547</span>, Cheerios: <span class="token punctuation">[</span><span class="token string">&#x27;509&#x27;</span>, <span class="token string">&#x27;468&#x27;</span><span class="token punctuation">]</span>
Top <span class="token number">2</span> neighbors of user <span class="token number">624</span>, Almond Delight: <span class="token punctuation">[</span><span class="token string">&#x27;468&#x27;</span>, <span class="token string">&#x27;509&#x27;</span><span class="token punctuation">]</span>
Top <span class="token number">2</span> neighbors of user <span class="token number">624</span>, Apple Jacks: <span class="token punctuation">[</span><span class="token string">&#x27;468&#x27;</span>, <span class="token string">&#x27;509&#x27;</span><span class="token punctuation">]</span>
Top <span class="token number">2</span> neighbors of user <span class="token number">73</span>, Bran Chex: <span class="token punctuation">[</span><span class="token string">&#x27;311&#x27;</span>, <span class="token string">&#x27;509&#x27;</span><span class="token punctuation">]</span>
</code></pre></div>
<p class="mb-4">Let&#x27;s take a look at the rating database after filling in all missing ratings:</p>
<div class="remark-highlight"><pre class="p-4 mb-4 bg-black"><code class="language-python">full_ratings
</code></pre></div>
<p class="mb-4"><img src="/assets/insights/2022-03-31-predict-product-ratings/full_rating.png" alt=""/></p>
<p class="mb-4">Pretty cool! Now we can suggest the products that are predicted to be highly rated to the users who haven&#x27;t watched those products before.</p>
<h2 class="text-3xl font-bold text-black mb-4">Conclusion</h2>
<p class="mb-4">You have just learned how to predict product ratings based on user-based collaborative filtering. I hope this article will give you the motivation to create your own recommendation system.</p>
<p class="mb-4">Feel free to play and fork the source code of this article <a style="color:#3273dc" href="https://github.com/ocelotconsulting/cereal-rating">here</a>.</p>
<h2 class="text-3xl font-bold text-black mb-4">Reference</h2>
<p class="mb-4">Katsov, I. (2018). <em>Introduction to algorithmic marketing</em>. Ilya Katsov.</p></div></section></main><footer class="bg-black text-white"><div class="container px-4 py-12 mx-auto lg:flex"><div class="px-4 lg:w-2/5 lg:pl-0 lg:pr-16 mb-8 lg:mb-0"><div class="w-full max-w-[230px] mb-10 mx-auto lg:mx-0"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 215 62.03"><g id="uuid-36b4f38d-82ab-4769-85a6-1757a5d82573" data-name="uuid-6f1e76c6-871c-4fd5-95c0-b7dc6214758d"><g id="uuid-7d66c6dc-fc9e-4ba1-b833-65066a7c4247" data-name="uuid-29bab21a-6fc1-46ac-aa88-74035bc2c5b9"><g id="uuid-b8891b53-f348-47c3-9d92-7338778cfcf4" data-name="uuid-4751f6df-72ec-41a6-a073-cf1f1b1dd6bc"><path id="uuid-e3d9be24-0379-461e-9289-5bbd376c2387" data-name="uuid-29c2d842-6d1f-44d3-9950-638fc274bebd" d="m31.13,0c5.08,0,9.87,1.22,14.11,3.38-1.55,1.95-2.6,4.54-4.88,5.31-2.94.99-6.07-1.51-9.17-1.55-3.38-.04-6.84,2.36-10.06,1.31-2.1-.68-3-3.08-4.32-4.96C21.1,1.26,25.97,0,31.13,0m26.53,14.83c2.92,4.74,4.61,10.32,4.61,16.3,0,15.17-10.86,27.81-25.22,30.57,1.12-.49,2.19-1.11,3.07-1.93.46-.42-.04-1.3.27-1.84.26-.46,1.02-.44,1.3-.89.56-.87.5-2.06,1.11-2.89.67-.92,1.77-1.44,2.62-2.2.5-.45.94-.96,1.43-1.43,2.85-2.73,6.51-4.8,8.57-8.15,1.74-2.82,2.23-6.34,2.38-9.64.13-2.73-1.14-5.34-1.55-8.04-.21-1.36-.6-2.77-.3-4.11.22-1,1.53-1.51,1.78-2.5.27-1.05-.02-2.16-.08-3.26m-30.42,47.19C11.88,60.11,0,47.01,0,31.13c0-5.93,1.66-11.48,4.55-16.2.03,1.2-.09,2.42.22,3.57.2.74,1.2,1.06,1.43,1.79.34,1.1.37,2.31.18,3.45-.29,1.77-1.34,3.35-1.61,5.12-.34,2.26-.58,4.6-.18,6.85.43,2.46,1.14,5.01,2.62,7.02,2.43,3.3,5.83,5.76,8.84,8.54,1.09,1.01,2.49,1.67,3.44,2.81.47.56.23,1.49.62,2.1.46.73,1.41,1.07,1.87,1.81.43.7.03,1.91.71,2.37,1.34.91,2.96,1.3,4.56,1.66" fill="#f60" fill-rule="evenodd"></path></g><g id="uuid-ce6c619f-feea-4dcb-9b23-c56e8af9b92a" data-name="uuid-178258df-3ee5-4b8a-85c8-9f993d6c858e"><path id="uuid-ddc55242-3c18-4ef0-b432-020824885082" data-name="uuid-653abd23-601c-4ba5-a9d5-31d185e024e6" d="m7.41,16.63c-.32-2.31-1.47-4.56-1.27-6.88.15-1.71.99-3.47,2.28-4.61,1.07-.94,2.72-1.21,4.13-1.06,1.68.18,3.34.96,4.66,2.01,1.99,1.58,2.62,4.93,5.03,5.72,2.86.93,5.94-1.2,8.95-1.17,2.76.03,5.54,2.26,8.15,1.38,2.65-.9,3.44-4.55,5.77-6.09,1.78-1.18,4.02-1.59,6.14-1.8.87-.09,1.85.31,2.44.95,1.13,1.25,2.28,2.76,2.44,4.45.22,2.42-1.08,4.74-1.38,7.15-.15,1.23.36,2.51.05,3.71-.23.88-1.39,1.34-1.59,2.22-.27,1.19.08,2.45.27,3.65.37,2.4,1.49,4.73,1.38,7.15-.14,2.94-.57,6.07-2.12,8.58-1.84,2.99-5.09,4.83-7.63,7.26-.43.42-.82.87-1.27,1.27-.75.68-1.73,1.14-2.33,1.96-.54.74-.49,1.8-.99,2.57-.25.39-.93.38-1.16.79-.27.48.17,1.26-.24,1.63-1.09,1-2.47,1.68-3.87,2.16-1.04.36-2.19.31-3.29.32-1.13,0-2.27,0-3.37-.26-1.71-.4-3.53-.7-4.98-1.69-.61-.41-.25-1.48-.63-2.11-.4-.65-1.25-.96-1.66-1.61-.35-.55-.14-1.37-.55-1.87-.84-1.02-2.09-1.61-3.06-2.5-2.68-2.47-5.7-4.66-7.86-7.6-1.32-1.79-1.94-4.06-2.33-6.25-.35-2-.14-4.08.16-6.09.23-1.57,1.17-2.98,1.43-4.55.17-1.01.14-2.09-.16-3.07-.2-.65-1.09-.93-1.27-1.59-.36-1.33-.07-2.76-.27-4.13" fill="#e0e0e0" fill-rule="evenodd"></path></g><g id="uuid-803098d2-eb8a-4d45-9390-6d7443b5f865" data-name="uuid-4a710bf9-375f-4b82-9254-04a9df0be943"><path id="uuid-0b0c7fdc-0632-4883-9269-254ef729e5e0" data-name="uuid-4fd63ea7-1664-45b6-b611-482476f0213d" d="m84.16,8.28c4.03,0,7.4,1.35,10.12,4.03,2.71,2.69,4.07,6.01,4.07,9.94s-1.35,7.2-4.07,9.92c-2.71,2.72-6.01,4.07-9.91,4.07s-7.27-1.35-9.99-4.05c-2.71-2.7-4.07-5.97-4.07-9.81,0-2.56.62-4.93,1.85-7.11,1.24-2.19,2.92-3.89,5.06-5.13,2.14-1.24,4.45-1.85,6.93-1.85m.13,2.61c-1.97,0-3.83.51-5.6,1.54-1.76,1.02-3.13,2.41-4.13,4.14-.99,1.74-1.48,3.68-1.48,5.81,0,3.16,1.09,5.83,3.29,8.01,2.19,2.17,4.83,3.26,7.92,3.26,2.06,0,3.97-.5,5.73-1.5,1.75-1,3.13-2.37,4.11-4.11.98-1.74,1.48-3.67,1.48-5.79s-.49-4.02-1.48-5.73c-.98-1.71-2.37-3.07-4.15-4.1-1.78-1.02-3.68-1.54-5.68-1.54m44.2,3l-2.1,1.61c-1.16-1.51-2.55-2.65-4.17-3.43-1.62-.78-3.4-1.17-5.35-1.17-2.12,0-4.09.51-5.9,1.53-1.81,1.02-3.21,2.39-4.21,4.11-.99,1.72-1.5,3.66-1.5,5.8,0,3.25,1.11,5.96,3.34,8.13,2.22,2.17,5.04,3.26,8.43,3.26,3.73,0,6.85-1.46,9.35-4.38l2.1,1.59c-1.33,1.69-2.98,3-4.97,3.92-1.98.93-4.2,1.38-6.65,1.38-4.66,0-8.33-1.55-11.02-4.65-2.26-2.61-3.39-5.78-3.39-9.48,0-3.9,1.37-7.17,4.1-9.84,2.73-2.66,6.15-3.99,10.27-3.99,2.49,0,4.73.49,6.73,1.48,2,.98,3.65,2.36,4.92,4.13m5.36-4.94h15.26v2.63h-12.6v8.33h12.49v2.61h-12.49v10.44h12.49v2.63h-15.16V8.94h0Zm19.86,0h2.68v24.06h10.22v2.57h-12.9V8.94h0Zm29.81-.67c4.03,0,7.4,1.35,10.12,4.03,2.71,2.69,4.07,6.01,4.07,9.94s-1.35,7.2-4.07,9.92c-2.71,2.72-6.01,4.07-9.91,4.07s-7.27-1.35-9.99-4.05c-2.71-2.7-4.07-5.97-4.07-9.81,0-2.56.62-4.93,1.85-7.11,1.24-2.19,2.92-3.89,5.06-5.13,2.14-1.24,4.45-1.85,6.93-1.85m.13,2.61c-1.97,0-3.83.51-5.6,1.54-1.76,1.02-3.13,2.41-4.13,4.14-.99,1.74-1.48,3.68-1.48,5.81,0,3.16,1.09,5.83,3.29,8.01,2.19,2.17,4.83,3.26,7.92,3.26,2.06,0,3.97-.5,5.73-1.5,1.76-1,3.12-2.37,4.11-4.11.98-1.74,1.48-3.67,1.48-5.79s-.49-4.02-1.48-5.73c-.98-1.71-2.37-3.07-4.15-4.1-1.78-1.02-3.68-1.54-5.68-1.54m16.76.65v-2.59h14.61v2.59h-5.94v24.04h-2.71V11.53h-5.96Z" fill="#e0e0e0"></path></g><g id="uuid-d7cf37d0-f044-4850-9a95-88987b5e275c" data-name="uuid-7f947cbe-8809-47f8-b515-3a5bf33c37c5"><path id="uuid-9146962c-1316-438e-8bb6-ac9a5dc1a957" data-name="uuid-dfcddcc4-7f8f-4ead-97ba-0cc39733b4c2" d="m79.4,45.95l-.73.56c-.4-.53-.89-.92-1.45-1.2s-1.19-.41-1.87-.41c-.74,0-1.43.18-2.06.53-.63.36-1.12.83-1.47,1.43-.35.6-.52,1.28-.52,2.03,0,1.13.39,2.08,1.17,2.84.78.76,1.76,1.14,2.94,1.14,1.3,0,2.39-.51,3.27-1.53l.73.56c-.46.59-1.04,1.05-1.73,1.37-.69.32-1.47.48-2.32.48-1.63,0-2.91-.54-3.85-1.62-.79-.91-1.18-2.02-1.18-3.31,0-1.36.48-2.5,1.43-3.44.95-.93,2.15-1.39,3.59-1.39.87,0,1.65.17,2.35.52.7.34,1.27.82,1.72,1.44m13.46-1.96c1.41,0,2.58.47,3.53,1.41.95.94,1.42,2.1,1.42,3.47s-.47,2.52-1.42,3.46c-.95.95-2.1,1.42-3.46,1.42s-2.54-.47-3.49-1.41c-.95-.94-1.42-2.09-1.42-3.43,0-.89.22-1.72.65-2.48.43-.76,1.02-1.36,1.77-1.79.75-.43,1.55-.65,2.42-.65m.05.91c-.69,0-1.34.18-1.95.54-.61.36-1.09.84-1.44,1.45-.34.61-.52,1.28-.52,2.03,0,1.1.38,2.04,1.15,2.8.76.76,1.69,1.14,2.77,1.14.72,0,1.39-.17,2-.52.61-.35,1.09-.83,1.44-1.44.34-.61.52-1.28.52-2.02s-.17-1.4-.52-2c-.34-.59-.83-1.07-1.45-1.43-.62-.36-1.29-.54-1.99-.54m13.95,8.62v-9.3h.2l6.18,7.12v-7.12h.92v9.3h-.21l-6.13-7.03v7.03h-.97Zm15.77-1.73l.79-.47c.56,1.02,1.2,1.53,1.93,1.53.31,0,.6-.07.88-.22.27-.14.48-.34.63-.59.14-.24.22-.5.22-.78,0-.31-.11-.62-.32-.92-.29-.41-.82-.91-1.59-1.49-.77-.59-1.26-1.01-1.45-1.27-.33-.44-.49-.91-.49-1.42,0-.41.1-.77.29-1.11s.47-.59.82-.79c.35-.19.73-.29,1.14-.29.44,0,.85.11,1.23.32.38.22.79.62,1.21,1.2l-.76.58c-.35-.46-.65-.77-.9-.92-.25-.15-.52-.22-.81-.22-.38,0-.68.11-.92.34-.24.23-.36.51-.36.84,0,.2.04.4.12.59.09.19.24.39.46.62.12.12.52.43,1.2.93.81.59,1.36,1.12,1.66,1.59.3.46.45.93.45,1.4,0,.68-.26,1.26-.77,1.76-.51.5-1.13.75-1.87.75-.57,0-1.08-.15-1.54-.45-.46-.3-.88-.81-1.27-1.51m14.6-7.57h.93v5.61c0,.67.01,1.08.04,1.24.05.37.16.67.32.92.17.25.43.45.78.62.35.16.7.25,1.06.25.31,0,.6-.06.88-.2.28-.13.52-.31.71-.54.19-.23.33-.51.42-.84.06-.24.1-.72.1-1.45v-5.61h.93v5.61c0,.83-.08,1.5-.24,2.01s-.49.96-.97,1.34c-.49.38-1.08.57-1.77.57-.75,0-1.39-.18-1.93-.54s-.89-.83-1.08-1.42c-.11-.36-.17-1.02-.17-1.96v-5.61h0Zm15.61,0h.94v8.4h3.57v.9h-4.51v-9.3h0Zm12.22.91v-.9h5.1v.9h-2.07v8.39h-.95v-8.39h-2.08Zm13.47-.9h.93v9.3h-.93v-9.3Zm10.23,9.3v-9.3h.2l6.18,7.12v-7.12h.92v9.3h-.21l-6.13-7.03v7.03h-.96,0Zm25.7-7.74l-.72.68c-.52-.51-1.09-.9-1.7-1.16s-1.22-.39-1.8-.39c-.73,0-1.42.18-2.08.54-.66.36-1.17.84-1.53,1.45-.36.61-.54,1.26-.54,1.94s.19,1.36.56,1.99c.38.63.89,1.13,1.55,1.49.66.36,1.39.54,2.17.54.96,0,1.77-.27,2.43-.81.66-.54,1.05-1.24,1.18-2.1h-2.96v-.9h4.01c0,1.44-.43,2.58-1.28,3.42-.84.85-1.97,1.27-3.39,1.27-1.72,0-3.08-.59-4.08-1.76-.77-.9-1.16-1.94-1.16-3.13,0-.88.22-1.7.66-2.46.44-.76,1.05-1.35,1.82-1.78.77-.43,1.64-.64,2.62-.64.79,0,1.53.14,2.22.43.7.28,1.37.74,2.04,1.37" fill="#e0e0e0"></path></g></g></g></svg></div><div class="flex items-center lg:px-0 md:px-16"><div class="w-1/3 pr-4"><img alt="Amazon Web Services" loading="lazy" width="679" height="187" decoding="async" data-nimg="1" style="color:transparent" src="/_next/static/media/aws-white.e205fdd0.png"/></div><div class="w-1/3 px-4 border-l border-r border-white/10"><img alt="Google Cloud" loading="lazy" width="640" height="174" decoding="async" data-nimg="1" style="color:transparent" src="/_next/static/media/gc-white.6fe6a761.png"/></div><div class="w-1/3 pl-4"><img alt="Microsoft Azure" loading="lazy" width="327" height="70" decoding="async" data-nimg="1" style="color:transparent" src="/_next/static/media/azure-white.0a539afc.png"/></div></div></div><div class="grow text-center lg:text-left mb-8 md:mb-0"><h3 class="text-lg font-bold mb-3">Who We Are</h3><nav class="leading-loose"><ul><li><a class="hover:text-accent" href="/">Home</a></li><li><a class="hover:text-accent" href="/about">About</a></li><li><a class="hover:text-accent" href="/careers">Careers</a></li><li><a class="hover:text-accent" href="/insights">Insights</a></li><li><a class="hover:text-accent" href="/case-studies">Case Studies</a></li></ul></nav></div><div class="grow text-center lg:text-left mb-8 md:mb-0"><h3 class="text-lg font-bold mb-3">Our Services</h3><nav class="leading-loose"><ul><li><a class="hover:text-accent" href="/services/cloud-transformation">Cloud Transformation</a></li><li><a class="hover:text-accent" href="/services/full-stack-development">Full-Stack Development</a></li><li><a class="hover:text-accent" href="/services/data-engineering">Data Engineering</a></li><li><a class="hover:text-accent" href="/services/data-science">Data Science</a></li><li><a class="hover:text-accent" href="/services/strategy-execution">Strategy &amp; Execution</a></li></ul></nav></div><div class="grow text-center lg:text-left"><h3 class="text-lg font-bold mb-3">Get In Touch</h3><div class="mb-3"><a class="flex items-center justify-center lg:justify-start hover:text-accent" href="tel:(314) 384-3225"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="phone" class="svg-inline--fa fa-phone mr-4" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M164.9 24.6c-7.7-18.6-28-28.5-47.4-23.2l-88 24C12.1 30.2 0 46 0 64C0 311.4 200.6 512 448 512c18 0 33.8-12.1 38.6-29.5l24-88c5.3-19.4-4.6-39.7-23.2-47.4l-96-40c-16.3-6.8-35.2-2.1-46.3 11.6L304.7 368C234.3 334.7 177.3 277.7 144 207.3L193.3 167c13.7-11.2 18.4-30 11.6-46.3l-40-96z"></path></svg><div>(314) 384-3225</div></a></div><div class="mb-3"><a class="flex items-center justify-center lg:justify-start hover:text-accent" href="https://goo.gl/maps/AGhk1LsPnY66R3VL8"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="location-pin" class="svg-inline--fa fa-location-pin mr-4" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M384 192c0 87.4-117 243-168.3 307.2c-12.3 15.3-35.1 15.3-47.4 0C117 435 0 279.4 0 192C0 86 86 0 192 0S384 86 384 192z"></path></svg><div>Ocelot Consulting<br/>11477 Olde Cabin Road<br/>Suite 320<br/>St. Louis, MO 63141</div></a></div><div><a class="flex items-center justify-center lg:justify-start hover:text-accent" href="https://www.linkedin.com/company/ocelot-consulting-llc/"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="linkedin-in" class="svg-inline--fa fa-linkedin-in mr-4" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z"></path></svg><div>LinkedIn</div></a></div></div></div><div class="border-t border-dark-gray p-4 text-xs"><div class="container mx-auto flex flex-col lg:flex-row justify-between"><div class="text-center">¬© <!-- -->2023<!-- --> Ocelot Consulting. All rights reserved.</div></div></div></footer><div class="fixed inset-0 z-30 hidden"><div class="absolute inset-0 z-0 bg-black/40"></div><div class="absolute top-0 bottom-0 right-0 bg-white text-lg overflow-hidden min-w-[300px]"><div class="p-10"><nav><ul><li class="py-4"><button class="w-full flex justify-between items-center"><span>Services</span><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="chevron-right" class="svg-inline--fa fa-chevron-right ml-2 text-sm" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-192 192c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L242.7 256 73.4 86.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l192 192z"></path></svg></button></li><li class="py-4"><a href="/about">About</a></li><li class="py-4"><a href="/case-studies">Case Studies</a></li><li class="py-4"><a href="/careers">Careers</a></li><li class="py-4"><a href="/insights">Insights</a></li><li class="py-4"><a class="lg:hidden" href="#">Contact</a></li></ul></nav></div><div class="absolute inset-0 bg-white p-10 transition-transform translate-x-full"><div class="flex justify-between items-center"><h3 class="text-accent uppercase tracking-widest">Services</h3><button><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="chevron-left" class="svg-inline--fa fa-chevron-left " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l192 192c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L77.3 256 246.6 86.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-192 192z"></path></svg></button></div><nav><ul><li class="py-4"><a href="/services">All Services</a></li><li class="py-4"><a href="/services/cloud-transformation">Cloud Transformation</a></li><li class="py-4"><a href="/services/full-stack-development">Full-Stack Development</a></li><li class="py-4"><a href="/services/data-engineering">Data Engineering</a></li><li class="py-4"><a href="/services/data-science">Data Science</a></li><li class="py-4"><a href="/services/strategy-execution">Strategy &amp; Execution</a></li></ul></nav></div></div></div><div class="fixed inset-0 z-30 hidden"><div class="absolute z-0 inset-0 bg-black/60"></div><div class="absolute top-0 bottom-0 right-0 bg-black text-white py-20 px-10 lg:w-[640px] max-w-full sm:w-screen md:w-screen"><button class="absolute top-8 right-8 text-3xl"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="xmark" class="svg-inline--fa fa-xmark " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M342.6 150.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192 210.7 86.6 105.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L146.7 256 41.4 361.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L192 301.3 297.4 406.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L237.3 256 342.6 150.6z"></path></svg></button><h2 class="text-5xl font-bold mb-8">Have a question?</h2><form action="https://9qpcx5jjib.execute-api.us-east-1.amazonaws.com/prod/" method="POST"><div class="grid grid-cols-1 gap-5"><input type="hidden" id="_to" name="_to" value="info@ocelotconsulting.com"/><input type="hidden" id="_honeypot" name="_honeypot" value=""/><input type="hidden" id="_recaptcha" name="_recaptcha" value=""/><input type="hidden" name="_redirect" value="https://ocelotconsulting.com/insights/predict-product-ratings"/><label class="block"><span>Name<span class="ml-1">*</span></span><input class="mt-1 block w-full text-black" type="text" name="name" required="" value=""/></label><label class="block"><span>Email<span class="ml-1">*</span></span><input class="mt-1 block w-full text-black" type="email" name="email" required="" value=""/></label><label class="block"><span>Phone</span><input class="mt-1 block w-full text-black" type="tel" name="phone" value=""/></label><label class="block"><span>Questions or Comments</span><textarea class="mt-1 block w-full text-black" name="message" rows="3"></textarea></label><button class="bg-accent text-white px-6 py-3 w-full" type="submit" disabled="">Submit</button></div></form></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/insights/predict-product-ratings","query":{},"buildId":"yo3mINIea42s1oz6L0drA","nextExport":true,"autoExport":true,"isFallback":false,"scriptLoader":[]}</script></body></html>